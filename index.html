---
layout: default
---

<!--
<div class="home">

<h1>{{ site.subtitle }}</h1>
{% include image.html url="" caption="sample adversarial examples" align="center" %}
{{ site.description }}
{% include image.html url="./_images/athena_fwk.png" caption="" width=900 align="center" %}
{{ site.description }}
</div>
-->

<!DOCTYPE html>
<html dir="ltr" lang="en">
<head>
    <meta charset="UTF-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>{{ site.title }}</title>
</head>
<body>
    <h1>{{ site.title }}: {{ site.subtitle }}</h1>
    <h3>by Ying Meng*, Jianhai Su, Jason O'Kane, Pooyan Jamshidi*</h3>
    <div id="main">
        <h2>Introduction</h2>
        {% include image.html url="./_images/athena_fwk.png" caption="" width=680 align="center" %}
        <p> Machine learning models have achieved human-level performance in many tasks, however, they are vulnerable to tiny imperceptible perturbations to its input. Such perturbed inputs are called <em>adversarial</em> examples. We propose Athena -- a framework for defending machine learning systems against adversarial attacks -- which ensembles various diverse weak defenses such as neural networks that were trained on disjointly transformed data. At test time, for a given input <strong><em>x</em></strong>, Athena first collects outputs from all weak defenses then uses some ensemble strategy (e.g., majority voting) to compute the final output. Athena is a defense framework that is (i) <em>extensible</em> so that one can add new weak defenses into or remove weak defenses from the framework anytime, (ii) <em>flexible</em> so that one can update the ensemble by replacing any weak defenses or ensemble strategy, and (iii) <em>general</em> so that one can use different type of machine learning models to train weak defenses.
        </p>

        <h2>Publication</h2>
        <ol>
            <li>
                Ying Meng, Jianhai Su, Jason O'Kane, Pooyan Jamshidi. <a href="https://arxiv.org/abs/2001.00308">Ensembles of Many Diverse Weak Defenses can be Strong: Defending Deep Neural Networks against Adversarial Attacks</a>, arxiv 2001.00308, 2020.
            </li>
        </ol>

        <h2>Code</h2>
        <a href="https://github.com/softsys4ai/athena">athena</a>
        <p></p>

        <h2>Talks</h2>
        <ol>
            <li>
                Pooyan Jamshidi. <a href="https://www.slideshare.net/pooyanjamshidi/ensembles-of-many-diverse-weak-defenses-can-be-strong-defending-deep-neural-networks-against-adversarial-attacks">Ensembles of Many Diverse Weak Defenses can be Strong: Defending Deep Neural Networks against Adversarial Attacks</a>. Augusta University, Augusta, Georgia, February 2020.
            </li>
        </ol>

        <h2>Future Works</h2>
        <p>Some future works based on Athena:</p>
        <ul>
            <li>Adversarial detector</li>
            <li>Automatically optimize weak defenses</li>
            <li>Representation learning in adversarial ML</li>
            <li>Defending against both sensitive and invariance adversarial perturbation</li>
        </ul>

        <h2>Acknowledgement</h2>
        <p>This project has been partially supported by:</p>
        <ul>
            <li>Google via GCP cloud research credits</li>
            <li>NASA (EPSCoR 521340-SC001)</li>
        </ul>
    </div>
</body>
</html>